{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction with Binary outcome     \n",
    "                                    \n",
    "Topics covered:                     \n",
    "  - Data cleaning & refactoring & feature engineering should be checked at official case studies repo    \n",
    "  - Winsorizing                     \n",
    "  - Basic models:                   \n",
    "    - Simple logit model            \n",
    "    - Cross validation with logit   \n",
    "    - Lasso with logit              \n",
    "  - Evaluation of model:            \n",
    "    - Calibration Curve,            \n",
    "    - Confusion Matrix              \n",
    "    - ROC, AUC                        \n",
    "  - Model comparison based on       \n",
    "    - RMSE or AUC                   \n",
    "  - Using a loss function           \n",
    "    - user-given loss function to pick 'best' threshold      \n",
    "  - Random Forest and CART          \n",
    "    - modeling probabilities rather than categorization    \n",
    "                                    \n",
    "Case studies:                       \n",
    "  - CH17A Predicting firm exit: probability and classification  \n",
    "                                    \n",
    "Dataset:\n",
    "     \n",
    "     bisnode-firms                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import patsy\n",
    "import sklearn.metrics as metrics\n",
    "import statsmodels.formula.api as smf\n",
    "from helper_functions import *\n",
    "from plotnine import *\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import (\n",
    "    LinearRegression,\n",
    "    LogisticRegression,\n",
    "    LogisticRegressionCV,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    auc,\n",
    "    brier_score_loss,\n",
    "    confusion_matrix,\n",
    "    mean_squared_error,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.tools.eval_measures import rmse\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bisnode dataset:\n",
    "Strongly advised to check the data cleaning/feature engineering codes: \n",
    "\n",
    "https://github.com/gabors-data-analysis/da_case_studies/blob/master/ch17-predicting-firm-exit/ch17-firm-exit-data-prep.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/bisnode_firms_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the default rate and show a graph for winsorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ggplot(data, aes(x=\"factor(default)\"))\n",
    "    + geom_histogram(aes(y=\"..count.. / sum(count)\"), size=0.1, fill=\"blue\", bins=3)\n",
    "    + labs(y=\"Probabilities\", x=\"0: Exists, 1: Defaults\")\n",
    "    + ylim(0, 1)\n",
    "    + theme_bw()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the sales against default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ggplot(data, aes(x=\"sales_mil_log\", y=\"default\"))\n",
    "    + geom_point(color=\"blue\")\n",
    "    + geom_smooth(method=\"lm\", formula=\"y ~ x + I(x**2)\", color=\"blue\", se=False)\n",
    "    + geom_smooth(method=\"loess\", color=\"red\", se=False, size=1.5, span=0.9)\n",
    "    + labs(x=\"sales_mil_log\", y=\"default\")\n",
    "    + theme_bw()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Winsorizing: variations for sales change \n",
    "\n",
    "you have to know your data (and theory) pretty well..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ggplot(data, aes(x=\"d1_sales_mil_log\", y=\"default\"))\n",
    "    + geom_point(color=\"blue\")\n",
    "    + geom_smooth(method=\"loess\", color=\"red\", se=False, size=1.5, span=0.9)\n",
    "    + labs(x=\"Growth rate (Diff of ln sales)\", y=\"default\")\n",
    "    + scale_x_continuous(limits=(-6, 10), breaks=np.arange(-5, 11, 5))\n",
    "    + theme_bw()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First measure for change in sales: take the sale change in logs but now winsorized!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ggplot(data, aes(x=\"d1_sales_mil_log\", y=\"default\"))\n",
    "    + geom_point(size=0.1, color=\"blue\")\n",
    "    + geom_smooth(method=\"loess\", color=\"red\", se=False, size=1.5, span=0.9)\n",
    "    + labs(x=\"Growth rate (Diff of ln sales)\", y=\"default\")\n",
    "    + scale_x_continuous(limits=(-1.5, 1.5), breaks=np.arange(-1.5, 1.6, 0.5))\n",
    "    + theme_bw()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ggplot(data, aes(x=\"d1_sales_mil_log\", y=\"d1_sales_mil_log_mod\"))\n",
    "    + geom_point(size=0.1, color=\"blue\")\n",
    "    + labs(\n",
    "        x=\"Growth rate (Diff of ln sales) (original)\",\n",
    "        y=\"Growth rate (Diff of ln sales) (winsorized)\",\n",
    "    )\n",
    "    + scale_x_continuous(limits=(-5, 5), breaks=np.arange(-5, 6, 1))\n",
    "    + scale_y_continuous(limits=(-3, 3), breaks=np.arange(-3, 4, 1))\n",
    "    + theme_bw()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building\n",
    "\n",
    "### Define variable sets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Main firm variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawvars = [\n",
    "    \"curr_assets\",\n",
    "    \"curr_liab\",\n",
    "    \"extra_exp\",\n",
    "    \"extra_inc\",\n",
    "    \"extra_profit_loss\",\n",
    "    \"fixed_assets\",\n",
    "    \"inc_bef_tax\",\n",
    "    \"intang_assets\",\n",
    "    \"inventories\",\n",
    "    \"liq_assets\",\n",
    "    \"material_exp\",\n",
    "    \"personnel_exp\",\n",
    "    \"profit_loss_year\",\n",
    "    \"sales\",\n",
    "    \"share_eq\",\n",
    "    \"subscribed_cap\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further financial variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qualityvars = [\"balsheet_flag\", \"balsheet_length\", \"balsheet_notfullyear\"]\n",
    "engvar = [\n",
    "    \"total_assets_bs\",\n",
    "    \"fixed_assets_bs\",\n",
    "    \"liq_assets_bs\",\n",
    "    \"curr_assets_bs\",\n",
    "    \"share_eq_bs\",\n",
    "    \"subscribed_cap_bs\",\n",
    "    \"intang_assets_bs\",\n",
    "    \"extra_exp_pl\",\n",
    "    \"extra_inc_pl\",\n",
    "    \"extra_profit_loss_pl\",\n",
    "    \"inc_bef_tax_pl\",\n",
    "    \"inventories_pl\",\n",
    "    \"material_exp_pl\",\n",
    "    \"profit_loss_year_pl\",\n",
    "    \"personnel_exp_pl\",\n",
    "]\n",
    "engvar2 = [\n",
    "    \"extra_profit_loss_pl_quad\",\n",
    "    \"inc_bef_tax_pl_quad\",\n",
    "    \"profit_loss_year_pl_quad\",\n",
    "    \"share_eq_bs_quad\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Flag variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engvar3 = []\n",
    "for col in data.columns:\n",
    "    if (\n",
    "        col.endswith(\"flag_low\")\n",
    "        or col.endswith(\"flag_high\")\n",
    "        or col.endswith(\"flag_error\")\n",
    "        or col.endswith(\"flag_zero\")\n",
    "    ):\n",
    "        engvar3.append(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Growth variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = [\n",
    "    \"d1_sales_mil_log_mod\",\n",
    "    \"d1_sales_mil_log_mod_sq\",\n",
    "    \"flag_low_d1_sales_mil_log\",\n",
    "    \"flag_high_d1_sales_mil_log\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Human capital related variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr = [\n",
    "    \"female\",\n",
    "    \"ceo_age\",\n",
    "    \"flag_high_ceo_age\",\n",
    "    \"flag_low_ceo_age\",\n",
    "    \"flag_miss_ceo_age\",\n",
    "    \"ceo_count\",\n",
    "    \"labor_avg_mod\",\n",
    "    \"flag_miss_labor_avg\",\n",
    "    \"foreign_management\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Firms history related variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firm = [\"age\", \"age2\", \"new\", \"C(ind2_cat)\", \"C(m_region_loc)\", \"C(urban_m)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interactions for logit, LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions1 = [\n",
    "    \"C(ind2_cat)*age\",\n",
    "    \"C(ind2_cat)*age2\",\n",
    "    \"C(ind2_cat)*d1_sales_mil_log_mod\",\n",
    "    \"C(ind2_cat)*sales_mil_log\",\n",
    "    \"C(ind2_cat)*ceo_age\",\n",
    "    \"C(ind2_cat)*foreign_management\",\n",
    "    \"C(ind2_cat)*female\",\n",
    "    \"C(ind2_cat)*C(urban_m)\",\n",
    "    \"C(ind2_cat)*labor_avg_mod\",\n",
    "]\n",
    "interactions2 = [\n",
    "    \"sales_mil_log*age\",\n",
    "    \"sales_mil_log*female\",\n",
    "    \"sales_mil_log*profit_loss_year_pl\",\n",
    "    \"sales_mil_log*foreign_management\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model setups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Simple logit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1 = [\n",
    "    \"sales_mil_log\",\n",
    "    \"sales_mil_log_sq\",\n",
    "    \"d1_sales_mil_log_mod\",\n",
    "    \"profit_loss_year_pl\",\n",
    "    \"C(ind2_cat)\",\n",
    "]\n",
    "M2 = [\n",
    "    \"sales_mil_log\",\n",
    "    \"sales_mil_log_sq\",\n",
    "    \"d1_sales_mil_log_mod\",\n",
    "    \"profit_loss_year_pl\",\n",
    "    \"fixed_assets_bs\",\n",
    "    \"share_eq_bs\",\n",
    "    \"curr_liab_bs \",\n",
    "    \"curr_liab_bs_flag_high \",\n",
    "    \"curr_liab_bs_flag_error\",\n",
    "    \"age\",\n",
    "    \"foreign_management\",\n",
    "    \"C(ind2_cat)\",\n",
    "]\n",
    "M3 = [\"sales_mil_log\", \"sales_mil_log_sq\"] + firm + engvar + d1\n",
    "M4 = (\n",
    "    [\"sales_mil_log\", \"sales_mil_log_sq\"]\n",
    "    + firm\n",
    "    + engvar\n",
    "    + engvar2\n",
    "    + engvar3\n",
    "    + d1\n",
    "    + hr\n",
    "    + qualityvars\n",
    ")\n",
    "M5 = (\n",
    "    [\"sales_mil_log\", \"sales_mil_log_sq\"]\n",
    "    + firm\n",
    "    + engvar\n",
    "    + engvar2\n",
    "    + engvar3\n",
    "    + d1\n",
    "    + hr\n",
    "    + qualityvars\n",
    "    + interactions1\n",
    "    + interactions2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. logit+LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logit_lasso_vars = (\n",
    "    [\"sales_mil_log\", \"sales_mil_log_sq\"]\n",
    "    + engvar\n",
    "    + engvar2\n",
    "    + engvar3\n",
    "    + d1\n",
    "    + hr\n",
    "    + firm\n",
    "    + qualityvars\n",
    "    + interactions1\n",
    "    + interactions2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. CART and RF (no interactions, no modified features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfvars = [\"sales_mil\", \"d1_sales_mil_log\"] + rawvars + hr + firm + qualityvars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick reminder about probability models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Linear probability model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_modelx2 = smf.ols(\"default~\" + \"+\".join(M2), data).fit(cov_type=\"HC1\")\n",
    "ols_modelx2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_modelx2 = smf.logit(\"default~\" + \"+\".join(M2), data).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_modelx2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Logit we need to calculate average marginal effects (dy/dx) to be able to interpret the coefficients (under some assumptions...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_modelx2.get_margeff().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the following:\n",
    "\n",
    "To get you more familiar with the steps of categorization and the notions we are going to:\n",
    "\n",
    "   1. Run simple logit and logit + lasso models and check the CV results\n",
    "   2. Introduce to the classification problem and show the tools of:\n",
    "       - what is the threshold value and how it relates to:\n",
    "       - confusion tables, ROC, AUC.\n",
    "       - refresh the calibration curve\n",
    "   3. Show how classification problem alters if you have a loss function:\n",
    "       - how to cross-validate your loss function (Youden index)\n",
    "       - and how this criterion will give you an 'optimal threshold' for your loss function\n",
    "   4. Finally we will cover CART and Random Forest\n",
    "   5. Compare the results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Separate train and holdout data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_holdout = train_test_split(data, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total\")\n",
    "print(data[\"default\"].value_counts(normalize=True))\n",
    "print(\"Train\")\n",
    "print(data_train[\"default\"].value_counts(normalize=True))\n",
    "print(\"Holdout\")\n",
    "print(data_holdout[\"default\"].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Predict probabilities with logit and Lasso with CV\n",
    "\n",
    "Specify 5 fold cross-validation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) cross validate logit models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up X-vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_model_vars = [M1, M2, M3, M4, M5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up Logit model object\n",
    "\n",
    "No regularisation needed so setting the paremeter to very high value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_value_logit = [1e20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_models = dict()\n",
    "CV_RMSE_folds = dict()\n",
    "\n",
    "for i, model_vars in enumerate(logit_model_vars):\n",
    "\n",
    "    model_equation = \"default~\" + \"+\".join(model_vars)\n",
    "    y_train, X_train = patsy.dmatrices(model_equation, data_train)\n",
    "\n",
    "    LRCV_brier = LogisticRegressionCV(\n",
    "        Cs=C_value_logit,\n",
    "        cv=k,\n",
    "        refit=True,\n",
    "        scoring=\"neg_brier_score\",\n",
    "        solver=\"newton-cg\",\n",
    "        tol=1e-7,\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    logit_models[\"M\" + str(i + 1)] = LRCV_brier.fit(X_train, y_train)\n",
    "\n",
    "    # Calculate RMSE on test for each fold\n",
    "    CV_RMSE_folds[\"M\" + str(i + 1)] = np.sqrt(\n",
    "        -1 * logit_models[\"M\" + str(i + 1)].scores_[1].ravel()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(CV_RMSE_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Logit + LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_equation = \"default~\" + \"+\".join(logit_lasso_vars)\n",
    "y_train, X_train = patsy.dmatrices(model_equation, data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalise X vars for Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_logitvars = pd.DataFrame(\n",
    "    StandardScaler().fit_transform(X_train),\n",
    "    columns=X_train.design_info.column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set regularization parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = list(10 ** np.arange(-1, -4.01, -1 / 3))\n",
    "n_obs = normalized_logitvars.shape[0] * 4 / 5\n",
    "C_values = [\n",
    "    1 / (l * n_obs) for l in lambdas\n",
    "]  # Cs are the inverse of regularization strength"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize and fit Logit Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logLasso_brier = LogisticRegressionCV(\n",
    "    Cs=C_values,\n",
    "    penalty=\"l1\",\n",
    "    cv=k,\n",
    "    refit=True,\n",
    "    scoring=\"neg_brier_score\",\n",
    "    solver=\"liblinear\",\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "logit_models[\"LASSO\"] = logLasso_brier.fit(normalized_logitvars, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See CV-fold RMSE-s (negative brier score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_summary_lasso = cv_summary(lambdas, C_values, logit_models[\"LASSO\"])\n",
    "cv_summary_lasso[\"mean_cv_score\"] = np.sqrt(cv_summary_lasso[\"mean_cv_score\"] * -1)\n",
    "cv_summary_lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save best lambda's index for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lambda_i = cv_summary_lasso[\"mean_cv_score\"].idxmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract CV test RMSE for the Lasso with best lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_RMSE_folds[\"LASSO\"] = np.sqrt(\n",
    "    -1 * logit_models[\"LASSO\"].scores_[1][:, cv_summary_lasso[\"mean_cv_score\"].idxmin()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  AUC, Calibration Curve, Confusion Matrix, ROC\n",
    "\n",
    "0. Calculate AUC for folds\n",
    "\n",
    "\n",
    "First, for logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_AUC_folds = dict()\n",
    "for i, model_vars in enumerate(logit_model_vars):\n",
    "\n",
    "    model_equation = \"default~\" + \"+\".join(model_vars)\n",
    "    y_train, X_train = patsy.dmatrices(model_equation, data_train)\n",
    "\n",
    "    LRCV_auc = LogisticRegressionCV(\n",
    "        Cs=C_value_logit,\n",
    "        cv=k,\n",
    "        refit=True,\n",
    "        scoring=\"roc_auc\",\n",
    "        solver=\"newton-cg\",\n",
    "        tol=1e-7,\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    logit_models[\"M\" + str(i + 1)] = LRCV_auc.fit(X_train, y_train)\n",
    "\n",
    "    # Calculate AUC on test for each fold\n",
    "    CV_AUC_folds[\"M\" + str(i + 1)] = logit_models[\"M\" + str(i + 1)].scores_[1].ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logLasso_auc = LogisticRegressionCV(\n",
    "    Cs=C_values,\n",
    "    penalty=\"l1\",\n",
    "    cv=k,\n",
    "    refit=True,\n",
    "    scoring=\"roc_auc\",\n",
    "    solver=\"liblinear\",\n",
    "    random_state=42,\n",
    ")\n",
    "logLasso_auc_fitted = logLasso_auc.fit(normalized_logitvars, y_train)\n",
    "\n",
    "CV_AUC_folds[\"LASSO\"] = logLasso_auc_fitted.scores_[1][\n",
    "    :, cv_summary_lasso[\"mean_cv_score\"].idxmin()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put a summary frame together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fits = pd.DataFrame(logit_models, index=[\"Model fit\"]).T\n",
    "\n",
    "summary = (\n",
    "    model_fits[\"Model fit\"]\n",
    "    .apply(lambda x: x.n_features_in_)\n",
    "    .to_frame(name=\"Number of Coefficients\")\n",
    ")\n",
    "\n",
    "summary.loc[\"LASSO\", \"Number of Coefficients\"] = len(\n",
    "    [i for i in model_fits.loc[\"LASSO\"].values[0].coef_[0] if i != 0]\n",
    ")\n",
    "\n",
    "summary[\"CV RMSE\"] = pd.DataFrame(CV_RMSE_folds).T.mean(axis=1)\n",
    "summary[\"CV AUC\"] = pd.DataFrame(CV_AUC_folds).T.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(x != 0 for x in model_fits.loc[\"LASSO\"].values[0].coef_[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(\n",
    "    [i for i in model_fits.loc[\"LASSO\"].values[0].coef_[0] if i != 0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take best model and estimate RMSE on holdout  \n",
    "\n",
    "M4, M5 and LASSO are practically the same - go with the simplest model, M4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_logit = logit_models[\"M4\"]\n",
    "model_equation = \"default~\" + \"+\".join(M4)\n",
    "_, X_holdout = patsy.dmatrices(model_equation, data_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best logit holdout RMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_holdout[\"best_logit_pred_proba\"] = best_logit.predict_proba(X_holdout)[:, 1]\n",
    "\n",
    "round(rmse(data_holdout[\"best_logit_pred_proba\"], data_holdout[\"default\"]), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Calibration curve\n",
    "\n",
    "how well do estimated vs actual event probabilities relate to each other?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breaks = np.linspace(0, (11) / 10, num=11, endpoint=False)\n",
    "\n",
    "data_holdout[\"prob_bin\"] = pd.cut(\n",
    "    data_holdout[\"best_logit_pred_proba\"], breaks, right=True, include_lowest=True\n",
    ")\n",
    "\n",
    "binned_data = (\n",
    "    data_holdout.groupby(\"prob_bin\")\n",
    "    .agg(\n",
    "        mean_prob=(\"best_logit_pred_proba\", \"mean\"),\n",
    "        mean_actual=(\"default\", \"mean\"),\n",
    "        n=(\"default\", \"size\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ggplot(binned_data, aes(\"mean_prob\", \"mean_actual\"))\n",
    "    + geom_line(color=\"blue\", size=1, show_legend=True)\n",
    "    + geom_point(color=\"blue\", size=1, alpha=0.7, show_legend=False, na_rm=True)\n",
    "    + geom_segment(\n",
    "        x=min(breaks),\n",
    "        xend=max(breaks),\n",
    "        y=min(breaks),\n",
    "        yend=max(breaks),\n",
    "        color=\"red\",\n",
    "        size=0.5,\n",
    "    )\n",
    "    + theme_bw()\n",
    "    + labs(x=\"Predicted event probability\", y=\"Actual event probability\")\n",
    "    + coord_cartesian(xlim=(0, 1), ylim=(0, 1))\n",
    "    + expand_limits(x=0.01, y=0.01)\n",
    "    + scale_y_continuous(expand=(0.01, 0.01), breaks=(np.arange(0, 1.1, 0.1)))\n",
    "    + scale_x_continuous(expand=(0.01, 0.01), breaks=(np.arange(0, 1.1, 0.1)))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Confusion table with different tresholds\n",
    "\n",
    "Default: the threshold 0.5 is used to convert probabilities to binary classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_class_prediction = best_logit.predict(X_holdout)\n",
    "\n",
    "values, counts = np.unique(logit_class_prediction.tolist(), return_counts=True)\n",
    "print(values[0], \" (no default): \", counts[0])\n",
    "print(values[1], \" (default): \", counts[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix: summarize different type of errors and successfully predicted cases\n",
    "\n",
    "positive = \"yes\": explicitly specify the positive case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_object1 = confusion_matrix(\n",
    "    data_holdout[\"default\"], logit_class_prediction, labels=[0, 1]\n",
    ")\n",
    "cm1 = pd.DataFrame(\n",
    "    cm_object1,\n",
    "    index=[\"Actul no defaul\", \"Actual default\"],\n",
    "    columns=[\"Predicted no default\", \"Predicted default\"],\n",
    ")\n",
    "cm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can apply different thresholds\n",
    "\n",
    "# 0.5 same as before\n",
    "holdout_prediction = np.where(data_holdout[\"best_logit_pred_proba\"] < 0.5, 0, 1)\n",
    "cm_object1b = confusion_matrix(\n",
    "    data_holdout[\"default\"], holdout_prediction, labels=[0, 1]\n",
    ")\n",
    "cm1b = pd.DataFrame(\n",
    "    cm_object1b,\n",
    "    index=[\"Actul no defaul\", \"Actual default\"],\n",
    "    columns=[\"Predicted no default\", \"Predicted default\"],\n",
    ")\n",
    "cm1b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sensible choice: mean of predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_predicted_default_prob = np.mean(data_holdout[\"best_logit_pred_proba\"])\n",
    "round(mean_predicted_default_prob, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_prediction = np.where(\n",
    "    data_holdout[\"best_logit_pred_proba\"] < mean_predicted_default_prob, 0, 1\n",
    ")\n",
    "cm_object2 = confusion_matrix(\n",
    "    data_holdout[\"default\"], holdout_prediction, labels=[0, 1]\n",
    ")\n",
    "cm2 = pd.DataFrame(\n",
    "    cm_object2,\n",
    "    index=[\"Actul no defaul\", \"Actual default\"],\n",
    "    columns=[\"Predicted no default\", \"Predicted default\"],\n",
    ")\n",
    "cm2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Visualize ROC (with thresholds in steps) on holdout\n",
    "\n",
    "What if we want to compare multiple thresholds?\n",
    "\n",
    "First, discrete ROC (with thresholds in steps) on holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.arange(0.05, 0.76, 0.05)\n",
    "thresholds = sorted(np.geomspace(0.95, 0.05, num=17))\n",
    "cm = dict()\n",
    "true_positive_rates = []\n",
    "false_positive_rates = []\n",
    "holdout_prediction = []\n",
    "for thr in thresholds:\n",
    "    holdout_prediction = np.where(data_holdout[\"best_logit_pred_proba\"] < thr, 0, 1)\n",
    "    cm_thr = confusion_matrix(data_holdout[\"default\"], holdout_prediction, labels=[0, 1])\n",
    "    cm[thr] = cm_thr\n",
    "    tn, fp, fn, tp = cm_thr.ravel()\n",
    "    true_positive_rates.append(tp / (tp + fn))\n",
    "    false_positive_rates.append(fp / (fp + tn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr_fpr_for_thresholds = pd.DataFrame(\n",
    "    {\n",
    "        \"thresholds\": thresholds,\n",
    "        \"true_positive_rates\": true_positive_rates,\n",
    "        \"false_positive_rates\": false_positive_rates,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ggplot(\n",
    "        tpr_fpr_for_thresholds,\n",
    "        aes(x=\"false_positive_rates\", y=\"true_positive_rates\", color=\"thresholds\"),\n",
    "    )\n",
    "    + labs(\n",
    "        x=\"False positive rate (1 - Specificity)\", y=\"True positive rate (Sensitivity)\"\n",
    "    )\n",
    "    + geom_point(size=4, alpha=0.8)\n",
    "    + scale_color_continuous(trans=\"reverse\", name=\"threshold\")\n",
    "    + scale_x_continuous(limits=(0, 1), breaks=np.arange(0, 1.01, 0.1))\n",
    "    + scale_y_continuous(limits=(0, 1), breaks=np.arange(0, 1.01, 0.1))\n",
    "    + theme_bw()\n",
    "    + theme(legend_position=\"right\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuous ROC on holdout with best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_roc_plot(data_holdout[\"default\"], data_holdout[\"best_logit_pred_proba\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. We have a loss function\n",
    "\n",
    "Introduce loss function\n",
    "\n",
    "Relative cost of of a false negative classification (as compared with a false positive classification)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP = 1\n",
    "FN = 10\n",
    "cost = FN / FP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prevalence, or the proportion of cases in the population (n.cases/(n.controls+n.cases))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevelance = y_train.sum() / len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw ROC Curve and find optimal threshold with loss function \n",
    "\n",
    "The optimal cut-off is the threshold that maximizes the distance to the identity (diagonal) line\n",
    "\n",
    "Iterate through:\n",
    " 1. models\n",
    " 2. Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_thresholds_cv = dict()\n",
    "expected_loss_cv = dict()\n",
    "fold5_threshold = dict()\n",
    "fold5_expected_loss = dict()\n",
    "fold5_all_coords = dict()\n",
    "\n",
    "for i, model_name in enumerate(logit_models):\n",
    "    best_thresholds = []\n",
    "    expected_loss = []\n",
    "\n",
    "    if model_name != \"LASSO\":\n",
    "        _, X = patsy.dmatrices(\"default ~\" + \"+\".join(logit_model_vars[i]), data_train)\n",
    "        X = pd.DataFrame(X)\n",
    "        c_index = 0\n",
    "    else:\n",
    "        X = normalized_logitvars\n",
    "        c_index = best_lambda_i\n",
    "    fold = 0\n",
    "    for train_index, test_index in k.split(X):\n",
    "        X_fold = X.iloc[test_index, :]\n",
    "        y_fold = data_train[\"default\"].iloc[test_index]\n",
    "        pred_fold = generate_fold_prediction(\n",
    "            logit_models[model_name], X_fold, fold, c_index\n",
    "        )\n",
    "        false_pos_rate, true_pos_rate, thresholds = roc_curve(y_fold, pred_fold)\n",
    "        optimal_threshold = sorted(\n",
    "            list(\n",
    "                zip(\n",
    "                    np.abs(\n",
    "                        true_pos_rate\n",
    "                        + (1 - prevelance) / (cost * prevelance) * (1 - false_pos_rate)\n",
    "                    ),\n",
    "                    thresholds,\n",
    "                )\n",
    "            ),\n",
    "            key=lambda i: i[0],\n",
    "            reverse=True,\n",
    "        )[0][1]\n",
    "        best_thresholds.append(optimal_threshold)\n",
    "        threshold_prediction = np.where(pred_fold < optimal_threshold, 0, 1)\n",
    "        tn, fp, fn, tp = confusion_matrix(\n",
    "            y_fold, threshold_prediction, labels=[0, 1]\n",
    "        ).ravel()\n",
    "        curr_exp_loss = (fp * FP + fn * FN) / len(y_fold)\n",
    "        expected_loss.append(curr_exp_loss)\n",
    "        fold = fold + 1\n",
    "\n",
    "    best_thresholds_cv[model_name] = np.mean(best_thresholds)\n",
    "    expected_loss_cv[model_name] = np.mean(expected_loss)\n",
    "\n",
    "    # for fold #5\n",
    "    fold5_threshold[model_name] = optimal_threshold\n",
    "    fold5_expected_loss[model_name] = curr_exp_loss\n",
    "\n",
    "    all_coords = pd.DataFrame(\n",
    "        {\n",
    "            \"false_pos\": false_pos_rate * sum(y_fold == 0),\n",
    "            \"true_pos\": true_pos_rate * sum(y_fold == 1),\n",
    "            \"false_neg\": sum(y_fold == 1) - true_pos_rate * sum(y_fold == 1),\n",
    "            \"true_neg\": sum(y_fold == 0) - false_pos_rate * sum(y_fold == 0),\n",
    "            \"pos\": sum(y_fold == 1),\n",
    "            \"neg\": sum(y_fold == 0),\n",
    "            \"n\": len(y_fold),\n",
    "            \"thresholds\": thresholds,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    fold5_all_coords[model_name] = all_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_with_lossfnc = pd.DataFrame(\n",
    "    best_thresholds_cv.items(), columns=[\"Model\", \"Avg of optimal thresholds\"]\n",
    ")\n",
    "summary_with_lossfnc[\"Threshold for Fold5\"] = fold5_threshold.values()\n",
    "summary_with_lossfnc[\"Avg expected loss\"] = expected_loss_cv.values()\n",
    "summary_with_lossfnc[\"Expected loss for Fold5\"] = fold5_expected_loss.values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary_with_lossfnc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create loss plot based on Fold5 in CV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_plot = \"M4\"# select model to plot\n",
    "create_loss_plot(\n",
    "    fold5_all_coords[model_to_plot],\n",
    "    fold5_threshold[model_to_plot],\n",
    "    fold5_expected_loss[model_to_plot],\n",
    "    FP,\n",
    "    FN,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create roc plot plot based on Fold5 in CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_roc_plot_with_optimal(\n",
    "    fold5_all_coords[model_to_plot], fold5_threshold[model_to_plot]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see our chosen model, M4's holdout expected loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_logit_optimal_treshold = best_thresholds_cv[\"M4\"]\n",
    "\n",
    "# Get expected loss on holdout\n",
    "holdout_treshold = np.where(\n",
    "    data_holdout[\"best_logit_pred_proba\"] < best_logit_optimal_treshold, 0, 1\n",
    ")\n",
    "tn, fp, fn, tp = confusion_matrix(\n",
    "    data_holdout[\"default\"], holdout_treshold, labels=[0, 1]\n",
    ").ravel()\n",
    "expected_loss_holdout = (fp * FP + fn * FN) / len(data_holdout[\"default\"])\n",
    "round(expected_loss_holdout, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CM on holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_object3 = confusion_matrix(data_holdout[\"default\"], holdout_treshold, labels=[0, 1])\n",
    "cm3 = pd.DataFrame(\n",
    "    cm_object3,\n",
    "    index=[\"Actul no defaul\", \"Actual default\"],\n",
    "    columns=[\"Predicted no default\", \"Predicted default\"],\n",
    ")\n",
    "cm3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICTION WITH RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, rfvars_train = patsy.dmatrices(\"default~\" + \"+\".join(rfvars), data_train)\n",
    "y_holdout, rfvars_holdout = patsy.dmatrices(\"default~\" + \"+\".join(rfvars), data_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph example for decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "data_for_graph = data_train[[\"sales_mil\", \"profit_loss_year\", \"foreign_management\"]]\n",
    "rf_for_graph = DecisionTreeClassifier(\n",
    "    ccp_alpha=0.0028, min_samples_leaf=100, max_depth=3, random_state=41\n",
    ").fit(data_for_graph, y_train)\n",
    "\n",
    "plt.figure()\n",
    "plt.figure(figsize=(11, 11))\n",
    "plot_tree(\n",
    "    rf_for_graph,\n",
    "    feature_names=data_for_graph.columns,\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    proportion=True,\n",
    "    fontsize=10,\n",
    ")\n",
    "plt.title(\"Decision tree\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability forest\n",
    "\n",
    "Split by gini, ratio of 1's in each tree, average over trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\n",
    "    \"max_features\": [5, 6, 7],\n",
    "    \"criterion\": [\"gini\"],\n",
    "    \"min_samples_split\": [11, 16],\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_forest = RandomForestClassifier(random_state=42, n_estimators=500, oob_score=True)\n",
    "prob_forest_grid = GridSearchCV(\n",
    "    prob_forest,\n",
    "    grid,\n",
    "    cv=k,\n",
    "    refit=\"roc_auc\",\n",
    "    scoring=[\"roc_auc\", \"neg_brier_score\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_forest_fit = prob_forest_grid.fit(rfvars_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create CV summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_forest_cv_results = pd.DataFrame(\n",
    "    {\n",
    "        \"max_features\": prob_forest_fit.cv_results_[\"param_max_features\"],\n",
    "        \"min_samples_split\": prob_forest_fit.cv_results_[\"param_min_samples_split\"],\n",
    "        \"cv_auc\": prob_forest_fit.cv_results_[\"mean_test_roc_auc\"],\n",
    "        \"cv_rmse\": np.sqrt(\n",
    "            prob_forest_fit.cv_results_[\"mean_test_neg_brier_score\"] * -1\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "\n",
    "prob_forest_cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain optimal parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mtry = prob_forest_fit.best_params_[\"max_features\"]\n",
    "best_min_node_size = prob_forest_fit.best_params_[\"min_samples_split\"]\n",
    "prob_forest_fit.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get average (ie over the folds) RMSE and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_forest_best_results = prob_forest_cv_results[\n",
    "    (prob_forest_cv_results.max_features == best_mtry)\n",
    "    & (prob_forest_cv_results.min_samples_split == best_min_node_size)\n",
    "]\n",
    "prob_forest_best_results_index = prob_forest_best_results.index.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.loc[\"RF\", \"Number of Coefficients\"] = \"n.a.\"\n",
    "summary.loc[\"RF\", \"CV RMSE\"] = prob_forest_best_results[\"cv_rmse\"].values[0]\n",
    "summary.loc[\"RF\", \"CV AUC\"] = prob_forest_best_results[\"cv_auc\"].values[0]\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract fold level RMSE and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_RMSE_folds[\"RF\"] = np.sqrt(\n",
    "    pd.DataFrame(prob_forest_fit.cv_results_)\n",
    "    .filter(like=\"_test_neg_brier_score\")\n",
    "    .loc[lambda x: x[\"rank_test_neg_brier_score\"] == 1]\n",
    "    .filter(like=\"split\")\n",
    "    .values[0]\n",
    "    * -1\n",
    ")\n",
    "CV_AUC_folds[\"RF\"] = (\n",
    "    pd.DataFrame(prob_forest_fit.cv_results_)\n",
    "    .filter(like=\"_test_roc_auc\")\n",
    "    .loc[lambda x: x[\"rank_test_roc_auc\"] == 1]\n",
    "    .filter(like=\"split\")\n",
    "    .values[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at foldwise RMSE and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(CV_RMSE_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(CV_AUC_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use loss function and search for best thresholds and expected loss over folds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_thresholds = list()\n",
    "expected_loss = list()\n",
    "rfvars_train = pd.DataFrame(rfvars_train)\n",
    "\n",
    "fold = 0\n",
    "for train_index, test_index in k.split(rfvars_train):\n",
    "    X_fold = rfvars_train.iloc[test_index, :]\n",
    "    y_fold = data_train[\"default\"].iloc[test_index]\n",
    "\n",
    "    X_fold_train = rfvars_train.iloc[train_index, :]\n",
    "    y_fold_train = data_train[\"default\"].iloc[train_index]\n",
    "\n",
    "    prob_forest_best = RandomForestClassifier(\n",
    "        random_state=42,\n",
    "        n_estimators=500,\n",
    "        oob_score=True,\n",
    "        criterion=\"gini\",\n",
    "        max_features=best_mtry,\n",
    "        min_samples_split=best_min_node_size,\n",
    "    )\n",
    "    prob_forest_best_fold = prob_forest_best.fit(X_fold_train, y_fold_train)\n",
    "    pred_fold = prob_forest_best_fold.predict_proba(X_fold)[:, 1]\n",
    "\n",
    "    false_pos_rate, true_pos_rate, threshold = roc_curve(y_fold, pred_fold)\n",
    "    best_threshold = sorted(\n",
    "        list(\n",
    "            zip(\n",
    "                np.abs(\n",
    "                    true_pos_rate\n",
    "                    + (1 - prevelance) / (cost * prevelance) * (1 - false_pos_rate)\n",
    "                ),\n",
    "                threshold,\n",
    "            )\n",
    "        ),\n",
    "        key=lambda x: x[0],\n",
    "        reverse=True,\n",
    "    )[0][1]\n",
    "    best_thresholds.append(best_threshold)\n",
    "    threshold_prediction = np.where(pred_fold < best_threshold, 0, 1)\n",
    "    tn, fp, fn, tp = confusion_matrix(\n",
    "        y_fold, threshold_prediction, labels=[0, 1]\n",
    "    ).ravel()\n",
    "    curr_exp_loss = (fp * FP + fn * FN) / len(y_fold)\n",
    "    expected_loss.append(curr_exp_loss)\n",
    "\n",
    "fold5_threshold_rf = best_threshold\n",
    "fold5_expected_loss_rf = curr_exp_loss\n",
    "\n",
    "all_coords_rf = pd.DataFrame(\n",
    "    {\n",
    "        \"false_pos\": false_pos_rate * sum(y_fold == 0),\n",
    "        \"true_pos\": true_pos_rate * sum(y_fold == 1),\n",
    "        \"false_neg\": sum(y_fold == 1) - true_pos_rate * sum(y_fold == 1),\n",
    "        \"true_neg\": sum(y_fold == 0) - false_pos_rate * sum(y_fold == 0),\n",
    "        \"pos\": sum(y_fold == 1),\n",
    "        \"neg\": sum(y_fold == 0),\n",
    "        \"n\": len(y_fold),\n",
    "        \"thresholds\": threshold,\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_loss_cv[\"RF\"] = np.mean(expected_loss)\n",
    "best_thresholds_cv[\"RF\"] = np.mean(best_thresholds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_summary = pd.DataFrame(\n",
    "    {\n",
    "        \"CV RMSE\": [round(prob_forest_best_results[\"cv_rmse\"].values[0], 3)],\n",
    "        \"CV AUC\": [round(prob_forest_best_results[\"cv_auc\"].values[0], 3)],\n",
    "        \"Avg of optimal thresholds\": [round(best_thresholds_cv[\"RF\"], 3)],\n",
    "        \"Threshold for Fold5\": [round(best_threshold, 3)],\n",
    "        \"Avg expected loss\": [round(expected_loss_cv[\"RF\"], 3)],\n",
    "        \"Expected loss for Fold5\": [round(curr_exp_loss, 3)],\n",
    "    }\n",
    ")\n",
    "\n",
    "rf_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create plots based on Fold5 in CV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_loss_plot(all_coords_rf, fold5_threshold_rf, fold5_expected_loss_rf, FP, FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_roc_plot_with_optimal(all_coords_rf, fold5_threshold_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take model to holdout and estimate RMSE, AUC and expected loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_forest_fit_best = prob_forest_fit.best_estimator_\n",
    "rf_predicted_probabilities_holdout = prob_forest_fit_best.predict_proba(rfvars_holdout)[\n",
    "    :, 1\n",
    "]\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_holdout, rf_predicted_probabilities_holdout))\n",
    "round(rmse_rf, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC AUC  on holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_rf = roc_auc_score(y_holdout, rf_predicted_probabilities_holdout)\n",
    "round(auc_rf, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Get expected loss on holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_treshold = np.where(\n",
    "    rf_predicted_probabilities_holdout < best_thresholds_cv[\"RF\"], 0, 1\n",
    ")\n",
    "tn, fp, fn, tp = confusion_matrix(y_holdout, holdout_treshold, labels=[0, 1]).ravel()\n",
    "expected_loss_holdout = (fp * FP + fn * FN) / len(y_holdout)\n",
    "round(expected_loss_holdout, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary[\"CV treshold\"] = best_thresholds_cv\n",
    "summary[\"CV expected Loss\"] = expected_loss_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "c01754e8627d0ea60fdf9a984fbf743943cf4db47884120dd04bfc512143b077"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
